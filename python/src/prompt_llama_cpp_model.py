

# def prompt_llama_cpp_model(model_file_path, model_configuration, prompt):
